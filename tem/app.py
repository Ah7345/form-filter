import io, zipfile, re
from pathlib import Path
import streamlit as st
from docxtpl import DocxTemplate  # For template filling
from docx import Document  # For reading source document

st.set_page_config(page_title="Ù…Ù„Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Multi-Job)", layout="centered")
st.title("Ù…Ù„Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ â€” Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù (DOCX â†’ DOCX)")
st.caption("Ù‚Ù… Ø¨Ø±ÙØ¹ Ù‚Ø§Ù„Ø¨ DOCX Ù…Ø¹ Ø¹Ù†Ø§ØµØ± Ù†Ø§Ø¦Ø¨Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ ÙˆÙ…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø¯Ø© ÙˆØ¸Ø§Ø¦Ù. Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ù…Ù„Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©.")

# Add processing mode selection
processing_mode = st.radio(
    "ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© / Processing Mode:",
    ["Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù / Multi-Job", "ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø© / Single Job"],
    horizontal=True
)

tmpl_file = st.file_uploader("Ø±ÙØ¹ Ø§Ù„Ù‚Ø§Ù„Ø¨ (DOCX) / Upload Template (DOCX)", type=["docx"])
st.info("ğŸ’¡ **Ù‡Ø§Ù…**: ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¹Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù†Ø§Ø¦Ø¨Ø© Ù…Ø«Ù„ {{ref}}ØŒ {{summary}}ØŒ {{channels}} ÙÙŠ Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„")

# Show template upload status
if tmpl_file:
    st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù‚Ø§Ù„Ø¨: {tmpl_file.name}")

# Define src_file outside the conditional blocks
if processing_mode == "Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù / Multi-Job":
    src_file = st.file_uploader("Ø±ÙØ¹ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (DOCX) / Upload Data Source (DOCX)", type=["docx"])
    st.info("ğŸ“‹ ÙˆØ¶Ø¹ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù: Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù„ÙƒÙ„ ÙˆØ¸ÙŠÙØ©")
else:
    src_file = st.file_uploader("Ø±ÙØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© (DOCX) / Upload Job Data (DOCX)", type=["docx"])
    st.info("ğŸ“„ ÙˆØ¶Ø¹ ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø©: Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

# Show source file upload status
if src_file:
    st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {src_file.name}")

# ---------- helpers ----------
def read_docx_paragraphs(file_bytes) -> list[str]:
    """
    Read paragraphs from a DOCX file using python-docx Document.
    This function is used to parse the source document for job information.
    """
    try:
        # Use Document for reading source files (more reliable for parsing)
        doc = Document(io.BytesIO(file_bytes))
        
        paras = []
        for p in doc.paragraphs:
            text = (p.text or "").strip()
            if text != "":
                paras.append(text)
        return paras
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù DOCX: {e}")
        st.error("ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù‡Ùˆ Ù…Ù„Ù DOCX ØµØ­ÙŠØ­")
        return []

def slice_jobs_from_source(paras: list[str], single_job: bool = False) -> dict:
    """
    Heuristic parser for job data:
    - A job block starts at a line that looks like a job title (Arabic words, not starting with digits or bullets),
      and within the next ~6 lines we see a numbered section like '1)'.
    - Sections inside each job: 1) ... 7)
    Returns: { job_title: { 'ref':..., 'summary':..., 'channels':..., 'levels':..., 'competencies':..., 'kpis':..., 'tasks':... } }
    """
    text = "\n".join(paras)

    # Split into candidates by lines that look like headings
    # We'll treat any line without leading digit and with Arabic letters as a potential job start.
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    job_indices = []
    
    # More flexible job detection - look for lines that could be job titles
    for i, line in enumerate(lines):
        # Check if line looks like a job title (has Arabic text, reasonable length, no leading numbers)
        if (len(line) > 3 and 
            re.search(r"[\u0600-\u06FF]", line) and  # Contains Arabic text
            not re.match(r"^\d", line) and            # Doesn't start with number
            not re.match(r"^[â€¢\-\*]", line) and      # Doesn't start with bullet
            not re.match(r"^\s*\d+\)", line)):       # Doesn't start with numbered section
            
            # Look ahead to see if this could be a job section
            # Check if within next 10 lines we have some numbered content
            window_lines = lines[i:i+10]
            window_text = "\n".join(window_lines)
            
            # More flexible pattern matching for numbered sections
            has_numbered_sections = (
                re.search(r"\b1\)", window_text) or           # 1)
                re.search(r"\b2\)", window_text) or           # 2)
                re.search(r"\b3\)", window_text) or           # 3)
                re.search(r"\b4\)", window_text) or           # 4)
                re.search(r"\b5\)", window_text) or           # 5)
                re.search(r"\b6\)", window_text) or           # 6)
                re.search(r"\b7\)", window_text) or           # 7)
                re.search(r"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", window_text) or        # Contains "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
                re.search(r"Ø§Ù„Ù…Ù„Ø®Øµ", window_text) or          # Contains "Ø§Ù„Ù…Ù„Ø®Øµ"
                re.search(r"Ø§Ù„Ù…Ù‡Ø§Ù…", window_text)             # Contains "Ø§Ù„Ù…Ù‡Ø§Ù…"
            )
            
            if has_numbered_sections:
                job_indices.append(i)

    # If no jobs found with strict criteria, try more relaxed approach
    if not job_indices:
        st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¸Ø§Ø¦Ù Ø¨Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØµØ§Ø±Ù…Ø©. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©...")
        
        # Look for any line with Arabic text that could be a job title
        for i, line in enumerate(lines):
            if (len(line) > 2 and 
                re.search(r"[\u0600-\u06FF]", line) and  # Contains Arabic text
                not re.match(r"^\d", line) and            # Doesn't start with number
                not re.match(r"^[â€¢\-\*]", line)):         # Doesn't start with bullet
                
                # Check if this line is followed by content (not just empty lines)
                next_lines = lines[i+1:i+5]
                if any(len(l.strip()) > 0 for l in next_lines):
                    job_indices.append(i)

    # Add end sentinel
    job_indices = sorted(set(job_indices))
    blocks = {}
    
    # For single job mode, only process the first job
    if single_job and job_indices:
        job_indices = job_indices[:1]
    
    for idx, start in enumerate(job_indices):
        end = job_indices[idx+1] if idx+1 < len(job_indices) else len(lines)
        chunk = "\n".join(lines[start:end]).strip()
        if not chunk:
            continue
        # Job title = first line
        job_title = lines[start]
        # Extract numbered sections
        def cap(pattern):
            m = re.search(pattern, chunk, re.S)
            return m.group(1).strip() if m else ""

        # More flexible pattern matching for sections
        ref_block      = cap(r"1\)\s*Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)")
        summary_block  = cap(r"2\)\s*Ø§Ù„Ù…Ù„Ø®Øµ.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ù…Ù„Ø®Øµ.*?\n(.*?)(?=\n\d\)|\Z)")
        channels_block = cap(r"3\)\s*Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„.*?\n(.*?)(?=\n\d\)|\Z)")
        levels_block   = cap(r"4\)\s*Ù…Ø³ØªÙˆÙŠØ§Øª.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ù…Ø³ØªÙˆÙŠØ§Øª.*?\n(.*?)(?=\n\d\)|\Z)")
        comp_block     = cap(r"5\)\s*Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)")
        kpis_block     = cap(r"6\)\s*Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡.*?\n(.*?)(?=\n\d\)|\Z)")
        tasks_block    = cap(r"7\)\s*Ø§Ù„Ù…Ù‡Ø§Ù….*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ù…Ù‡Ø§Ù….*?\n(.*?)(?=\n\d\)|\Z)")

        blocks[job_title] = {
            "ref": ref_block,
            "summary": summary_block,
            "channels": channels_block,
            "levels": levels_block,
            "competencies": comp_block,
            "kpis": kpis_block,
            "tasks": tasks_block
        }

    return blocks

def build_filled_docx_bytes(template_bytes: bytes, job_title: str, data: dict) -> bytes:
    """
    Build a filled DOCX using DocxTemplate to fill existing table cells with placeholders.
    This preserves the original table structure and fills the blanks instead of adding new content.
    """
    # Create DocxTemplate from the template bytes
    doc = DocxTemplate(io.BytesIO(template_bytes))
    
    # Prepare context data for template rendering
    # Add job_title to the context so it can be used in the template
    context = {
        "job_title": job_title,
        "ref": data.get("ref", ""),
        "summary": data.get("summary", ""),
        "channels": data.get("channels", ""),
        "levels": data.get("levels", ""),
        "competencies": data.get("competencies", ""),
        "kpis": data.get("kpis", ""),
        "tasks": data.get("tasks", "")
    }
    
    # Render the template with the context data
    # This will replace all {{placeholders}} in tables and paragraphs
    doc.render(context)
    
    # Save the rendered document to bytes
    out = io.BytesIO()
    doc.save(out)
    out.seek(0)
    return out.read()

def zip_many(named_bytes: dict[str, bytes]) -> bytes:
    bio = io.BytesIO()
    with zipfile.ZipFile(bio, "w", compression=zipfile.ZIP_DEFLATED) as z:
        for fname, b in named_bytes.items():
            z.writestr(fname, b)
    bio.seek(0)
    return bio.read()

# ---------- main ----------
if st.button("Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ù…Ù„ÙˆØ¡Ø© / Generate Filled Forms", type="primary", disabled=(tmpl_file is None or src_file is None)):
    try:
        tmpl_bytes = tmpl_file.read()
        src_bytes  = src_file.read()

        # parse jobs
        paras = read_docx_paragraphs(src_bytes)
        single_job_mode = processing_mode == "ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø© / Single Job"
        jobs = slice_jobs_from_source(paras, single_job_mode)

        if not jobs:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£ÙŠ ÙˆØ¸Ø§Ø¦Ù. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ù„Ù Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª DOCX ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø£Ù‚Ø³Ø§Ù… Ù…Ø±Ù‚Ù…Ø© Ø£Ùˆ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø«Ù„ 'Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'ØŒ 'Ø§Ù„Ù…Ù„Ø®Øµ'ØŒ 'Ø§Ù„Ù…Ù‡Ø§Ù…'.")
        else:
            if single_job_mode:
                st.success(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø©. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
            else:
                st.success(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(jobs)} ÙˆØ¸ÙŠÙØ©(ÙˆØ¸Ø§Ø¦Ù). Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
            
            files = {}
            for job_title, data in jobs.items():
                doc_bytes = build_filled_docx_bytes(tmpl_bytes, job_title, data)
                safe_name = re.sub(r'[\\/*?:"<>|]', "-", job_title)
                files[f"{safe_name}.docx"] = doc_bytes
                st.download_button(f"ØªØ­Ù…ÙŠÙ„: {job_title} / Download: {job_title}", data=doc_bytes, file_name=f"{safe_name}.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

            # zip all (only for multi-job mode)
            if not single_job_mode and len(files) > 1:
                zip_bytes = zip_many(files)
                st.download_button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„ (ZIP) / Download ALL (ZIP)", data=zip_bytes, file_name="filled_jobs.zip", mime="application/zip")

    except Exception as e:
        st.error(f"Ø®Ø·Ø£: {e}")

st.markdown("""
**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø© / Important Notes**
- **ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¹Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù†Ø§Ø¦Ø¨Ø©** Ù…Ø«Ù„ `{{ref}}`ØŒ `{{summary}}`ØŒ `{{channels}}` ÙÙŠ Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
- **Ù„Ø§ ÙŠØ¶ÙŠÙ Ù…Ø­ØªÙˆÙ‰ Ø¬Ø¯ÙŠØ¯** ÙÙŠ Ø£Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø©ØŒ Ø¨Ù„ ÙŠÙ…Ù„Ø£ Ø§Ù„Ø®Ù„Ø§ÙŠØ§ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
- **ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ ØªØ®Ø·ÙŠØ· Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„** Ø§Ù„Ø£ØµÙ„ÙŠ ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
- **Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Ø§Ø¦Ø¨Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©**:
  - `{{job_title}}` - Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ¸ÙŠÙØ©
  - `{{ref}}` - Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©
  - `{{summary}}` - Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø§Ù…
  - `{{channels}}` - Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„
  - `{{levels}}` - Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
  - `{{competencies}}` - Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª
  - `{{kpis}}` - Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
  - `{{tasks}}` - Ø§Ù„Ù…Ù‡Ø§Ù…

**Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø§Ù„Ø¨**:
```
| Ø§Ù„Ù‚Ø³Ù… | Ø§Ù„Ù…Ø­ØªÙˆÙ‰ |
|-------|---------|
| Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙˆØ¸ÙŠÙØ© | {{job_title}} |
| Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© | {{ref}} |
| Ø§Ù„Ù…Ù„Ø®Øµ | {{summary}} |
```
""")