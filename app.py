import io, zipfile, re, json
from pathlib import Path
import streamlit as st
from docxtpl import DocxTemplate  # For template filling
from docx import Document  # For reading source document

st.set_page_config(page_title="Ù…Ù„Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Multi-Job)", layout="centered")
st.title("Ù…Ù„Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ â€” Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù (DOCX â†’ DOCX)")
st.caption("Ù‚Ù… Ø¨Ø±ÙØ¹ Ù‚Ø§Ù„Ø¨ DOCX ÙˆÙ…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø¯Ø© ÙˆØ¸Ø§Ø¦Ù. Ø³ÙŠÙ‚ÙˆÙ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ù…Ù„Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")

# Add processing mode selection
processing_mode = st.radio(
    "ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© / Processing Mode:",
    ["Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù / Multi-Job", "ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø© / Single Job"],
    horizontal=True
)

tmpl_file = st.file_uploader("Ø±ÙØ¹ Ø§Ù„Ù‚Ø§Ù„Ø¨ (DOCX) / Upload Template (DOCX)", type=["docx"])
st.info("ğŸ’¡ **Ù‡Ø§Ù…**: Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Ø§Ø¦Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙˆÙ…Ù„Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„")

# Show template upload status
if tmpl_file:
    st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù‚Ø§Ù„Ø¨: {tmpl_file.name}")

# Define src_file outside the conditional blocks
if processing_mode == "Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù / Multi-Job":
    src_file = st.file_uploader("Ø±ÙØ¹ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (DOCX) / Upload Data Source (DOCX)", type=["docx"])
    st.info("ğŸ“‹ ÙˆØ¶Ø¹ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù: Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù„ÙƒÙ„ ÙˆØ¸ÙŠÙØ©")
else:
    src_file = st.file_uploader("Ø±ÙØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© (DOCX) / Upload Job Data (DOCX)", type=["docx"])
    st.info("ğŸ“„ ÙˆØ¶Ø¹ ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø©: Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

# Show source file upload status
if src_file:
    st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {src_file.name}")

# ---------- helpers ----------
def create_template_structure():
    """
    Create the standard template structure with placeholders
    """
    template_structure = {
        "Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ù‡Ù†ÙŠ": {
            "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ù…Ù‡Ù†Ø©": {
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©": "{{main_group}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©": "{{main_group_code}}",
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©": "{{sub_group}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©": "{{sub_group_code}}",
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©": "{{secondary_group}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©": "{{secondary_group_code}}",
                "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙˆØ­Ø¯Ø§Øª": "{{units_group}}",
                "Ø±Ù…Ø² Ø§Ù„ÙˆØ­Ø¯Ø§Øª": "{{units_code}}",
                "Ø§Ù„Ù…Ù‡Ù†Ø©": "{{profession}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ù‡Ù†Ø©": "{{profession_code}}",
                "Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ù…Ù„": "{{work_location}}",
                "Ø§Ù„Ù…Ø±ØªØ¨Ø©": "{{rank}}"
            },
            "Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…Ù‡Ù†Ø©": "{{summary}}",
            "Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„": {
                "Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©": [
                    {
                        "Ø§Ù„Ø¬Ù‡Ø©": "{{internal_party_1}}",
                        "Ø§Ù„ØºØ±Ø¶ Ù…Ù† Ø§Ù„ØªÙˆØ§ØµÙ„": "{{internal_purpose_1}}"
                    }
                ],
                "Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©": [
                    {
                        "Ø§Ù„Ø¬Ù‡Ø©": "{{external_party_1}}",
                        "Ø§Ù„ØºØ±Ø¶ Ù…Ù† Ø§Ù„ØªÙˆØ§ØµÙ„": "{{external_purpose_1}}"
                    }
                ]
            },
            "Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‡Ù†Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©": [
                {
                    "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ù‡Ù†Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ": "{{level_1}}",
                    "Ø±Ù…Ø² Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ù‡Ù†ÙŠ": "{{level_code_1}}",
                    "Ø§Ù„Ø¯ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ": "{{role_1}}",
                    "Ø§Ù„ØªØ¯Ø±Ø¬ Ø§Ù„Ù…Ù‡Ù†ÙŠ (Ø§Ù„Ù…Ø±ØªØ¨Ø©)": "{{progression_1}}"
                }
            ],
            "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª": {
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ©": ["{{behavioral_comp_1}}", "{{behavioral_comp_2}}", "{{behavioral_comp_3}}"],
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©": ["{{core_comp_1}}", "{{core_comp_2}}", "{{core_comp_3}}"],
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø¯ÙŠØ©": ["{{leadership_comp_1}}", "{{leadership_comp_2}}", "{{leadership_comp_3}}"],
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©": ["{{technical_comp_1}}", "{{technical_comp_2}}", "{{technical_comp_3}}"]
            }
        },
        "Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙˆØµÙ Ø§Ù„ÙØ¹Ù„ÙŠ": {
            "Ø§Ù„Ù…Ù‡Ø§Ù…": {
                "Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù‚ÙŠØ§Ø¯ÙŠØ©/Ø§Ù„Ø¥Ø´Ø±Ø§ÙÙŠØ©": ["{{leadership_task_1}}", "{{leadership_task_2}}", "{{leadership_task_3}}"],
                "Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ®ØµØµÙŠØ©": ["{{specialized_task_1}}", "{{specialized_task_2}}", "{{specialized_task_3}}"],
                "Ù…Ù‡Ø§Ù… Ø£Ø®Ø±Ù‰ Ø¥Ø¶Ø§ÙÙŠØ©": ["{{additional_task_1}}", "{{additional_task_2}}", "{{additional_task_3}}"]
            },
            "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© ÙˆØ§Ù„ÙÙ†ÙŠØ©": {
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ©": [
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "1",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{behavioral_comp_1}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_1}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "2",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{behavioral_comp_2}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_2}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "3",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{behavioral_comp_3}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_3}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "4",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{behavioral_comp_4}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_4}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "5",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{behavioral_comp_5}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_5}}"
                    }
                ],
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©": [
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "1",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{technical_comp_1}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_1}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "2",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{technical_comp_2}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_2}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "3",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{technical_comp_3}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_3}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "4",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{technical_comp_4}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_4}}"
                    },
                    {
                        "Ø§Ù„Ø±Ù‚Ù…": "5",
                        "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": "{{technical_comp_5}}",
                        "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "{{proficiency_5}}"
                    }
                ]
            },
            "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù†ÙŠ": [
                {
                    "Ø§Ù„Ø±Ù‚Ù…": "1",
                    "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ": "{{kpi_1}}",
                    "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "{{measurement_1}}"
                },
                {
                    "Ø§Ù„Ø±Ù‚Ù…": "2",
                    "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ": "{{kpi_2}}",
                    "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "{{measurement_2}}"
                },
                {
                    "Ø§Ù„Ø±Ù‚Ù…": "3",
                    "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ": "{{kpi_3}}",
                    "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "{{measurement_3}}"
                },
                {
                    "Ø§Ù„Ø±Ù‚Ù…": "4",
                    "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ": "{{kpi_4}}",
                    "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "{{measurement_4}}"
                }
            ]
        }
    }
    return template_structure

def create_template_with_placeholders(template_bytes: bytes) -> bytes:
    """
    Create a new template with placeholders based on the standard structure
    """
    try:
        # Create a new document with placeholders
        doc = Document()
        
        # Add title
        title = doc.add_heading("Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ù‡Ù†ÙŠ", 0)
        
        # Add sections with placeholders
        sections = [
            ("1- Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ù…Ù‡Ù†Ø©", [
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {{main_group}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©: {{main_group_code}}",
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©: {{sub_group}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©: {{sub_group_code}}",
                "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©: {{secondary_group}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©: {{secondary_group_code}}",
                "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙˆØ­Ø¯Ø§Øª: {{units_group}}",
                "Ø±Ù…Ø² Ø§Ù„ÙˆØ­Ø¯Ø§Øª: {{units_code}}",
                "Ø§Ù„Ù…Ù‡Ù†Ø©: {{profession}}",
                "Ø±Ù…Ø² Ø§Ù„Ù…Ù‡Ù†Ø©: {{profession_code}}",
                "Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ù…Ù„: {{work_location}}",
                "Ø§Ù„Ù…Ø±ØªØ¨Ø©: {{rank}}"
            ]),
            ("2- Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…Ù‡Ù†Ø©", ["{{summary}}"]),
            ("3- Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„", [
                "Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©: {{internal_party_1}} - {{internal_purpose_1}}",
                "Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©: {{external_party_1}} - {{external_purpose_1}}"
            ]),
            ("4- Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‡Ù†Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©", [
                "Ø§Ù„Ù…Ø³ØªÙˆÙ‰ 1: {{level_1}} ({{level_code_1}}) - {{role_1}} - {{progression_1}}"
            ]),
            ("5- Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª", [
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ©: {{behavioral_comp_1}}, {{behavioral_comp_2}}, {{behavioral_comp_3}}",
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©: {{core_comp_1}}, {{core_comp_2}}, {{core_comp_3}}",
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø¯ÙŠØ©: {{leadership_comp_1}}, {{leadership_comp_2}}, {{leadership_comp_3}}",
                "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©: {{technical_comp_1}}, {{technical_comp_2}}, {{technical_comp_3}}"
            ])
        ]
        
        for section_title, items in sections:
            doc.add_heading(section_title, level=1)
            for item in items:
                doc.add_paragraph(item)
            doc.add_paragraph("")  # Add space between sections
        
        # Add Form B
        doc.add_heading("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙˆØµÙ Ø§Ù„ÙØ¹Ù„ÙŠ", level=0)
        
        # Tasks section
        doc.add_heading("1- Ø§Ù„Ù…Ù‡Ø§Ù…", level=1)
        doc.add_paragraph("Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù‚ÙŠØ§Ø¯ÙŠØ©/Ø§Ù„Ø¥Ø´Ø±Ø§ÙÙŠØ©: {{leadership_task_1}}, {{leadership_task_2}}, {{leadership_task_3}}")
        doc.add_paragraph("Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ®ØµØµÙŠØ©: {{specialized_task_1}}, {{specialized_task_2}}, {{specialized_task_3}}")
        doc.add_paragraph("Ù…Ù‡Ø§Ù… Ø£Ø®Ø±Ù‰ Ø¥Ø¶Ø§ÙÙŠØ©: {{additional_task_1}}, {{additional_task_2}}, {{additional_task_3}}")
        
        # Competencies section
        doc.add_heading("2- Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© ÙˆØ§Ù„ÙÙ†ÙŠØ©", level=1)
        doc.add_paragraph("Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ©:")
        for i in range(1, 6):
            doc.add_paragraph(f"{i}- {{behavioral_comp_{i}}} - Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†: {{proficiency_{i}}}")
        
        doc.add_paragraph("Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©:")
        for i in range(1, 6):
            doc.add_paragraph(f"{i}- {{technical_comp_{i}}} - Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†: {{proficiency_{i}}}")
        
        # Performance section
        doc.add_heading("3- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù†ÙŠ", level=1)
        for i in range(1, 5):
            doc.add_paragraph(f"{i}- {{kpi_{i}}} - Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³: {{measurement_{i}}}")
        
        # Save the new template
        out = io.BytesIO()
        doc.save(out)
        out.seek(0)
        return out.read()
        
    except Exception as e:
        st.error(f"Error creating template: {e}")
        return template_bytes

def read_docx_paragraphs(file_bytes) -> list[str]:
    """
    Read paragraphs from a DOCX file using python-docx Document.
    This function is used to parse the source document for job information.
    """
    try:
        # Use Document for reading source files (more reliable for parsing)
        doc = Document(io.BytesIO(file_bytes))
        
        paras = []
        for p in doc.paragraphs:
            text = (p.text or "").strip()
            if text != "":
                paras.append(text)
        return paras
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù DOCX: {e}")
        return []

def slice_jobs_from_source(paras: list[str], single_job: bool = False) -> dict:
    """
    Heuristic parser for job data:
    - A job block starts at a line that looks like a job title (Arabic words, not starting with digits or bullets),
      and within the next ~6 lines we see a numbered section like '1)'.
    - Sections inside each job: 1) ... 7)
    Returns: { job_title: { 'ref':..., 'summary':..., 'channels':..., 'levels':..., 'competencies':..., 'kpis':..., 'tasks':... } }
    """
    text = "\n".join(paras)

    # Split into candidates by lines that look like headings
    # We'll treat any line without leading digit and with Arabic letters as a potential job start.
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    job_indices = []
    
    # More flexible job detection - look for lines that could be job titles
    for i, line in enumerate(lines):
        # Check if line looks like a job title (has Arabic text, reasonable length, no leading numbers)
        if (len(line) > 3 and 
            re.search(r"[\u0600-\u06FF]", line) and  # Contains Arabic text
            not re.match(r"^\d", line) and            # Doesn't start with number
            not re.match(r"^[â€¢\-\*]", line) and      # Doesn't start with bullet
            not re.match(r"^\s*\d+\)", line)):       # Doesn't start with numbered section
            
            # Look ahead to see if this could be a job section
            # Check if within next 10 lines we have some numbered content
            window_lines = lines[i:i+10]
            window_text = "\n".join(window_lines)
            
            # More flexible pattern matching for numbered sections
            has_numbered_sections = (
                re.search(r"\b1\)", window_text) or           # 1)
                re.search(r"\b2\)", window_text) or           # 2)
                re.search(r"\b3\)", window_text) or           # 3)
                re.search(r"\b4\)", window_text) or           # 4)
                re.search(r"\b5\)", window_text) or           # 5)
                re.search(r"\b6\)", window_text) or           # 6)
                re.search(r"\b7\)", window_text) or           # 7)
                re.search(r"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", window_text) or        # Contains "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
                re.search(r"Ø§Ù„Ù…Ù„Ø®Øµ", window_text) or          # Contains "Ø§Ù„Ù…Ù„Ø®Øµ"
                re.search(r"Ø§Ù„Ù…Ù‡Ø§Ù…", window_text)             # Contains "Ø§Ù„Ù…Ù‡Ø§Ù…"
            )
            
            if has_numbered_sections:
                job_indices.append(i)

    # If no jobs found with strict criteria, try more relaxed approach
    if not job_indices:
        st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ¸Ø§Ø¦Ù Ø¨Ø§Ù„Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØµØ§Ø±Ù…Ø©. Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± Ù…Ø±ÙˆÙ†Ø©...")
        
        # Look for any line with Arabic text that could be a job title
        for i, line in enumerate(lines):
            if (len(line) > 2 and 
                re.search(r"[\u0600-\u06FF]", line) and  # Contains Arabic text
                not re.match(r"^\d", line) and            # Doesn't start with number
                not re.match(r"^[â€¢\-\*]", line)):         # Doesn't start with bullet
                
                # Check if this line is followed by content (not just empty lines)
                next_lines = lines[i+1:i+5]
                if any(len(l.strip()) > 0 for l in next_lines):
                    job_indices.append(i)

    # Add end sentinel
    job_indices = sorted(set(job_indices))
    blocks = {}
    
    # For single job mode, only process the first job
    if single_job and job_indices:
        job_indices = job_indices[:1]
    
    for idx, start in enumerate(job_indices):
        end = job_indices[idx+1] if idx+1 < len(job_indices) else len(lines)
        chunk = "\n".join(lines[start:end]).strip()
        if not chunk:
            continue
        # Job title = first line
        job_title = lines[start]
        # Extract numbered sections
        def cap(pattern):
            m = re.search(pattern, chunk, re.S)
            return m.group(1).strip() if m else ""

        # More flexible pattern matching for sections
        ref_block      = cap(r"1\)\s*Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)")
        summary_block  = cap(r"2\)\s*Ø§Ù„Ù…Ù„Ø®Øµ.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ù…Ù„Ø®Øµ.*?\n(.*?)(?=\n\d\)|\Z)")
        channels_block = cap(r"3\)\s*Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„.*?\n(.*?)(?=\n\d\)|\Z)")
        levels_block   = cap(r"4\)\s*Ù…Ø³ØªÙˆÙŠØ§Øª.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ù…Ø³ØªÙˆÙŠØ§Øª.*?\n(.*?)(?=\n\d\)|\Z)")
        comp_block     = cap(r"5\)\s*Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª.*?\n(.*?)(?=\n\d\)|\Z)")
        kpis_block     = cap(r"6\)\s*Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡.*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡.*?\n(.*?)(?=\n\d\)|\Z)")
        tasks_block    = cap(r"7\)\s*Ø§Ù„Ù…Ù‡Ø§Ù….*?\n(.*?)(?=\n\d\)|\Z)") or cap(r"Ø§Ù„Ù…Ù‡Ø§Ù….*?\n(.*?)(?=\n\d\)|\Z)")

        blocks[job_title] = {
            "ref": ref_block,
            "summary": summary_block,
            "channels": channels_block,
            "levels": levels_block,
            "competencies": comp_block,
            "kpis": kpis_block,
            "tasks": tasks_block
        }

    return blocks

def add_table(doc, label, data):
    """
    Add a 2-column table to the document with proper RTL formatting.
    
    Args:
        doc: Document object
        label: Table title/label
        data: Data to display (dict, list, or string)
    """
    # Create table based on data type
    if isinstance(data, dict):
        # For dictionaries, create table with key-value pairs
        rows = len(data) + 1  # +1 for header
        table = doc.add_table(rows=rows, cols=2)
        table.style = 'Table Grid'
        
        # Header row
        header_cells = table.rows[0].cells
        header_cells[0].text = label
        header_cells[1].text = "Ø§Ù„Ù‚ÙŠÙ…Ø©"
        
        # Make header bold and center
        for cell in header_cells:
            for paragraph in cell.paragraphs:
                paragraph.alignment = 1  # Center alignment
                for run in paragraph.runs:
                    run.bold = True
        
        # Data rows
        for i, (key, value) in enumerate(data.items(), 1):
            row_cells = table.rows[i].cells
            row_cells[0].text = str(key)
            row_cells[1].text = str(value) if value else ""
            
            # Make label column bold
            for paragraph in row_cells[0].paragraphs:
                for run in paragraph.runs:
                    run.bold = True
    
    elif isinstance(data, list):
        # For lists, create table with items
        if not data:
            # Empty list - create single row
            table = doc.add_table(rows=2, cols=2)
            table.style = 'Table Grid'
            header_cells = table.rows[0].cells
            header_cells[0].text = label
            header_cells[1].text = "Ø§Ù„Ù‚ÙŠÙ…Ø©"
            
            # Make header bold and center
            for cell in header_cells:
                for paragraph in cell.paragraphs:
                    paragraph.alignment = 1
                    for run in paragraph.runs:
                        run.bold = True
            
            # Empty data row
            data_cells = table.rows[1].cells
            data_cells[0].text = "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª"
            data_cells[1].text = ""
        else:
            # List with items
            rows = len(data) + 1  # +1 for header
            table = doc.add_table(rows=rows, cols=2)
            table.style = 'Table Grid'
            
            # Header row
            header_cells = table.rows[0].cells
            header_cells[0].text = label
            header_cells[1].text = "Ø§Ù„Ù‚ÙŠÙ…Ø©"
            
            # Make header bold and center
            for cell in header_cells:
                for paragraph in cell.paragraphs:
                    paragraph.alignment = 1
                    for run in paragraph.runs:
                        run.bold = True
            
            # Data rows
            for i, item in enumerate(data, 1):
                row_cells = table.rows[i].cells
                if isinstance(item, dict):
                    # Handle dictionary items (like competencies with number, competency, level)
                    if 'Ø§Ù„Ø±Ù‚Ù…' in item and 'Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©' in item:
                        row_cells[0].text = f"{item.get('Ø§Ù„Ø±Ù‚Ù…', '')} - {item.get('Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©', '')}"
                        row_cells[1].text = str(item.get('Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†', ''))
                    elif 'Ø§Ù„Ø±Ù‚Ù…' in item and 'Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ' in item:
                        row_cells[0].text = f"{item.get('Ø§Ù„Ø±Ù‚Ù…', '')} - {item.get('Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ', '')}"
                        row_cells[1].text = str(item.get('Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³', ''))
                    else:
                        # Generic dictionary handling
                        row_cells[0].text = str(list(item.keys())[0]) if item else ""
                        row_cells[1].text = str(list(item.values())[0]) if item else ""
                else:
                    # Simple list item
                    row_cells[0].text = str(i)
                    row_cells[1].text = str(item)
    
    else:
        # For strings or other types, create single row
        table = doc.add_table(rows=2, cols=2)
        table.style = 'Table Grid'
        
        # Header row
        header_cells = table.rows[0].cells
        header_cells[0].text = label
        header_cells[1].text = "Ø§Ù„Ù‚ÙŠÙ…Ø©"
        
        # Make header bold and center
        for cell in header_cells:
            for paragraph in cell.paragraphs:
                paragraph.alignment = 1
                for run in paragraph.runs:
                    run.bold = True
        
        # Data row
        data_cells = table.rows[1].cells
        data_cells[0].text = label
        data_cells[1].text = str(data) if data else ""
        
        # Make label column bold
        for paragraph in data_cells[0].paragraphs:
            for run in paragraph.runs:
                run.bold = True
    
    # Set RTL alignment for all cells
    for row in table.rows:
        for cell in row.cells:
            for paragraph in cell.paragraphs:
                paragraph.alignment = 2  # RTL alignment
    
    # Add spacing after table
    doc.add_paragraph("")

def build_filled_docx_bytes(template_bytes: bytes, job_title: str, data: dict) -> bytes:
    """
    Build a filled DOCX using tables for structured layout with proper RTL formatting.
    This creates a clean, professional document with tables instead of plain paragraphs.
    """
    try:
        # Create a new document
        doc = Document()
        
        # Add title - centered and bold
        title = doc.add_heading(f"Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ù‡Ù†ÙŠ â€” {job_title}", 0)
        title.alignment = 1  # Center alignment
        
        # Add spacing after title
        doc.add_paragraph("")
        
        # Section 1: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ù…Ù‡Ù†Ø© (Job Reference Data)
        ref_data = {
            "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©": data.get("ref", ""),
            "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©": "001",
            "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©": data.get("ref", ""),
            "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙØ±Ø¹ÙŠØ©": "001",
            "Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©": data.get("ref", ""),
            "Ø±Ù…Ø² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©": "001",
            "Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ÙˆØ­Ø¯Ø§Øª": data.get("ref", ""),
            "Ø±Ù…Ø² Ø§Ù„ÙˆØ­Ø¯Ø§Øª": "001",
            "Ø§Ù„Ù…Ù‡Ù†Ø©": job_title,
            "Ø±Ù…Ø² Ø§Ù„Ù…Ù‡Ù†Ø©": "001",
            "Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ù…Ù„": "Ø§Ù„Ù…Ù‚Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ",
            "Ø§Ù„Ù…Ø±ØªØ¨Ø©": "Ø£ÙˆÙ„"
        }
        add_table(doc, "1- Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© Ù„Ù„Ù…Ù‡Ù†Ø©", ref_data)
        
        # Section 2: Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…Ù‡Ù†Ø© (General Summary)
        summary_data = data.get("summary", "") or "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ø®Øµ"
        add_table(doc, "2- Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù…Ù‡Ù†Ø©", summary_data)
        
        # Section 3: Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ (Communication Channels)
        channels_data = {
            "Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©": data.get("channels", ""),
            "Ø¬Ù‡Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©": data.get("channels", "")
        }
        add_table(doc, "3- Ù‚Ù†ÙˆØ§Øª Ø§Ù„ØªÙˆØ§ØµÙ„", channels_data)
        
        # Section 4: Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‡Ù†Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ© (Standard Profession Levels)
        levels_data = {
            "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ù‡Ù†Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠ": data.get("levels", ""),
            "Ø±Ù…Ø² Ø§Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ù‡Ù†ÙŠ": "L1",
            "Ø§Ù„Ø¯ÙˆØ± Ø§Ù„Ù…Ù‡Ù†ÙŠ": data.get("levels", ""),
            "Ø§Ù„ØªØ¯Ø±Ø¬ Ø§Ù„Ù…Ù‡Ù†ÙŠ (Ø§Ù„Ù…Ø±ØªØ¨Ø©)": "Ø£ÙˆÙ„"
        }
        add_table(doc, "4- Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‡Ù†Ø© Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©", levels_data)
        
        # Section 5: Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª (Competencies)
        competencies_data = {
            "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ©": data.get("competencies", ""),
            "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©": data.get("competencies", ""),
            "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ù‚ÙŠØ§Ø¯ÙŠØ©": data.get("competencies", ""),
            "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ©": data.get("competencies", "")
        }
        add_table(doc, "5- Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª", competencies_data)
        
        # Section 6: Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù†ÙŠ (Performance Management)
        kpis_data = {
            "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ 1": data.get("kpis", ""),
            "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ 2": data.get("kpis", ""),
            "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ 3": data.get("kpis", ""),
            "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡ 4": data.get("kpis", "")
        }
        add_table(doc, "6- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù†ÙŠ", kpis_data)
        
        # Section 7: Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks)
        tasks_data = {
            "Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù‚ÙŠØ§Ø¯ÙŠØ©/Ø§Ù„Ø¥Ø´Ø±Ø§ÙÙŠØ©": data.get("tasks", ""),
            "Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØªØ®ØµØµÙŠØ©": data.get("tasks", ""),
            "Ù…Ù‡Ø§Ù… Ø£Ø®Ø±Ù‰ Ø¥Ø¶Ø§ÙÙŠØ©": data.get("tasks", "")
        }
        add_table(doc, "7- Ø§Ù„Ù…Ù‡Ø§Ù…", tasks_data)
        
        # Add Form B: Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙˆØµÙ Ø§Ù„ÙØ¹Ù„ÙŠ (Actual Description Form)
        doc.add_heading("Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ÙˆØµÙ Ø§Ù„ÙØ¹Ù„ÙŠ", level=1)
        doc.add_paragraph("")
        
        # Form B Section 1: Ø§Ù„Ù…Ù‡Ø§Ù… (Tasks)
        form_b_tasks = [
            {"Ø§Ù„Ø±Ù‚Ù…": "1", "Ø§Ù„Ù…Ù‡Ù…Ø©": data.get("tasks", "")},
            {"Ø§Ù„Ø±Ù‚Ù…": "2", "Ø§Ù„Ù…Ù‡Ù…Ø©": data.get("tasks", "")},
            {"Ø§Ù„Ø±Ù‚Ù…": "3", "Ø§Ù„Ù…Ù‡Ù…Ø©": data.get("tasks", "")}
        ]
        add_table(doc, "1- Ø§Ù„Ù…Ù‡Ø§Ù…", form_b_tasks)
        
        # Form B Section 2: Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© ÙˆØ§Ù„ÙÙ†ÙŠØ© (Behavioral and Technical Competencies)
        behavioral_competencies = [
            {"Ø§Ù„Ø±Ù‚Ù…": "1", "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": data.get("competencies", ""), "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "Ù…ØªÙ‚Ø¯Ù…"},
            {"Ø§Ù„Ø±Ù‚Ù…": "2", "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": data.get("competencies", ""), "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "Ù…ØªÙ‚Ø¯Ù…"},
            {"Ø§Ù„Ø±Ù‚Ù…": "3", "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": data.get("competencies", ""), "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "Ù…ØªÙ‚Ø¯Ù…"},
            {"Ø§Ù„Ø±Ù‚Ù…": "4", "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": data.get("competencies", ""), "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "Ù…ØªÙ‚Ø¯Ù…"},
            {"Ø§Ù„Ø±Ù‚Ù…": "5", "Ø§Ù„Ø¬Ø¯Ø§Ø±Ø©": data.get("competencies", ""), "Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥ØªÙ‚Ø§Ù†": "Ù…ØªÙ‚Ø¯Ù…"}
        ]
        add_table(doc, "2- Ø§Ù„Ø¬Ø¯Ø§Ø±Ø§Øª Ø§Ù„Ø³Ù„ÙˆÙƒÙŠØ© ÙˆØ§Ù„ÙÙ†ÙŠØ©", behavioral_competencies)
        
        # Form B Section 3: Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù†ÙŠ (Performance Management)
        performance_indicators = [
            {"Ø§Ù„Ø±Ù‚Ù…": "1", "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡": data.get("kpis", ""), "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "Ù‚ÙŠØ§Ø³ Ù…Ø¨Ø§Ø´Ø±"},
            {"Ø§Ù„Ø±Ù‚Ù…": "2", "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡": data.get("kpis", ""), "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "Ù‚ÙŠØ§Ø³ Ù…Ø¨Ø§Ø´Ø±"},
            {"Ø§Ù„Ø±Ù‚Ù…": "3", "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡": data.get("kpis", ""), "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "Ù‚ÙŠØ§Ø³ Ù…Ø¨Ø§Ø´Ø±"},
            {"Ø§Ù„Ø±Ù‚Ù…": "4", "Ù…Ø¤Ø´Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡": data.get("kpis", ""), "Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù‚ÙŠØ§Ø³": "Ù‚ÙŠØ§Ø³ Ù…Ø¨Ø§Ø´Ø±"}
        ]
        add_table(doc, "3- Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù†ÙŠ", performance_indicators)
        
        # Save the rendered document to bytes
        out = io.BytesIO()
        doc.save(out)
        out.seek(0)
        return out.read()
        
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ù„Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨: {e}")
        return template_bytes

def zip_many(named_bytes: dict[str, bytes]) -> bytes:
    bio = io.BytesIO()
    with zipfile.ZipFile(bio, "w", compression=zipfile.ZIP_DEFLATED) as z:
        for fname, b in named_bytes.items():
            z.writestr(fname, b)
    bio.seek(0)
    return bio.read()

# ---------- main ----------
if st.button("Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ù…Ù„ÙˆØ¡Ø© / Generate Filled Forms", type="primary", disabled=(tmpl_file is None or src_file is None)):
    try:
        tmpl_bytes = tmpl_file.read()
        src_bytes  = src_file.read()

        # Show template structure
        st.write("**ğŸ“‹ Template Structure Created:**")
        template_structure = create_template_structure()
        st.json(template_structure)
        
        # Create template with placeholders
        st.write("**ğŸ”§ Creating template with placeholders...**")
        template_with_placeholders = create_template_with_placeholders(tmpl_bytes)
        
        # Show download for template with placeholders
        st.download_button(
            "ğŸ“¥ Download Template with Placeholders",
            data=template_with_placeholders,
            file_name="template_with_placeholders.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )

        # parse jobs
        paras = read_docx_paragraphs(src_bytes)
        single_job_mode = processing_mode == "ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø© / Single Job"
        jobs = slice_jobs_from_source(paras, single_job_mode)

        if not jobs:
            st.error("Ù„Ù… ÙŠØªÙ… Ø§ÙƒØªØ´Ø§Ù Ø£ÙŠ ÙˆØ¸Ø§Ø¦Ù. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ù…Ù„Ù Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª DOCX ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ø£Ù‚Ø³Ø§Ù… Ù…Ø±Ù‚Ù…Ø© Ø£Ùˆ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù…Ø«Ù„ 'Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª'ØŒ 'Ø§Ù„Ù…Ù„Ø®Øµ'ØŒ 'Ø§Ù„Ù…Ù‡Ø§Ù…'.")
        else:
            if single_job_mode:
                st.success(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù ÙˆØ¸ÙŠÙØ© ÙˆØ§Ø­Ø¯Ø©. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
            else:
                st.success(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(jobs)} ÙˆØ¸ÙŠÙØ©(ÙˆØ¸Ø§Ø¦Ù). Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬...")
            
            files = {}
            for job_title, data in jobs.items():
                doc_bytes = build_filled_docx_bytes(template_with_placeholders, job_title, data)
                safe_name = re.sub(r'[\\/*?:"<>|]', "-", job_title)
                files[f"{safe_name}.docx"] = doc_bytes
                st.download_button(f"ØªØ­Ù…ÙŠÙ„: {job_title} / Download: {job_title}", data=doc_bytes, file_name=f"{safe_name}.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")

            # zip all (only for multi-job mode)
            if not single_job_mode and len(files) > 1:
                zip_bytes = zip_many(files)
                st.download_button("ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙƒÙ„ (ZIP) / Download ALL (ZIP)", data=zip_bytes, file_name="filled_jobs.zip", mime="application/zip")

    except Exception as e:
        st.error(f"Ø®Ø·Ø£: {e}")

st.markdown("""
**Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ù…Ù‡Ù…Ø© / Important Notes**

## ğŸ¯ **ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¢Ù† / How the App Works Now:**

1. **ÙŠØ±ÙØ¹ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù‚Ø§Ù„Ø¨** (Ø£ÙŠ Ù‚Ø§Ù„Ø¨ DOCX)
2. **Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠÙ†Ø´Ø¦ Ù‚Ø§Ù„Ø¨ Ø¬Ø¯ÙŠØ¯** Ù…Ø¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Ø§Ø¦Ø¨Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
3. **ÙŠØ±ÙØ¹ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù…ØµØ¯Ø±** Ù…Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
4. **Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠÙ…Ù„Ø£ Ø§Ù„Ù‚Ø§Ù„Ø¨** Ø¨Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ„ ÙˆØ¸ÙŠÙØ©
5. **ÙŠØ­ØµÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù…Ù…Ù„ÙˆØ¡Ø©** Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

## âœ… **Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©:**
- **Ø¥Ù†Ø´Ø§Ø¡ ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Ø§Ø¦Ø¨Ø©** - Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ø¥Ø¶Ø§ÙØªÙ‡Ø§ ÙŠØ¯ÙˆÙŠØ§Ù‹
- **Ù…Ù„Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„ÙØ§Ø±ØºØ©** ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
- **Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©**
- **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ø© ÙˆØ¸Ø§Ø¦Ù** ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
- **ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ù…Ø¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Ø§Ø¦Ø¨Ø©** Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠ

## ğŸ”§ **Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:**
1. Ø§Ø±ÙØ¹ Ù‚Ø§Ù„Ø¨Ùƒ
2. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ù„Ø¨ Ù…Ø¹ Ø¹Ù†Ø§ØµØ± Ù†Ø§Ø¦Ø¨Ø©
3. Ø§Ø±ÙØ¹ Ù…ØµØ¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
4. Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ù…Ù…Ù„ÙˆØ¡Ø© Ø¬Ø§Ù‡Ø²Ø©
""")